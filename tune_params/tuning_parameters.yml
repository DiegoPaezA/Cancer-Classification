# Tuning Parameters

log_reg:
  C: [0.001, 0.01, 0.1, 1, 10, 100, 1000]
  penalty: ['l1', 'l2', 'elasticnet', 'none']
  solver: ['liblinear', 'saga', 'lbfgs', 'newton-cg']
  max_iter: [100, 1000, 10000]

naive_bayes:
  var_smoothing: [1e-09, 1e-08, 1e-07, 1e-06, 1e-05, 1e-04, 1e-03, 1e-02, 1e-01]

knn:
  n_neighbors: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
  weights: ['uniform', 'distance']
  algorithm: ['auto', 'ball_tree', 'kd_tree', 'brute']
  leaf_size: [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
  p: [1, 2]

svm:
  C: [0.1, 1, 10, 100, 1000]
  kernel: ['linear', 'rbf']
  gamma: ['scale', 'auto']
  coef0: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]

xgb:
  learning_rate: [0.01, 0.1, 0.2, 0.3, 0.4, 0.5]
  max_depth: [3, 4, 5, 6, 7, 8, 9, 10]
  n_estimators: [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]
  subsample: [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  colsample_bytree: [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  reg_lambda: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  gamma: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  scale_pos_weight: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]